#hkb
#__author__="harpreet kaur bargota"
#__email__="harpreet.bargota@agr.gc.ca"
#__Project__="Faba bean Feature extraction pipeline (Step2)"

#References: 
#SegmentAnthing (MetaAI): https://github.com/facebookresearch/segment-anything 
# Reference paper: @article{kirillov2023segany, title={Segment Anything}, author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Doll{\'a}r, Piotr and Girshick, Ross},journal={arXiv:2304.02643},year={2023}}

#Feature extraction: 
#scikit-image library for image processing: Stéfan van der Walt, Johannes L. Schönberger, Juan Nunez-Iglesias, François Boulogne, Joshua D. Warner, Neil Yager, Emmanuelle Gouillart, Tony Yu and the scikit-image contributors. scikit-image: Image processing in Python. PeerJ 2:e453 (2014) https://doi.org/10.7717/peerj.453
#https://scikit-image.org/docs/stable/api/skimage.measure.html


#import the libraries required for analysis

import argparse
import pandas as pd
import seaborn as sns
import numpy as np
import cv2
import os
import glob
import matplotlib.pyplot as plt
#from scipy.stats import (pearsonr, ttest_rel, f_oneway, spearmanr, shapiro, levene, wilcoxon, kruskal, skew, kurtosis )
import warnings
warnings.filterwarnings(action='ignore')
from skimage import measure
from skimage.measure import label, regionprops, regionprops_table
from collections import Counter


#Function to define the shape of beans based on the values of shapefactor1,2,3,4 from faba bean images
def classify_shape(row):
    """
        Identifies the shape of beans based on the shapefactors.

        Arguments:
          row: the data for each seed. 

        Returns: str: shape of beans.    
        
    """
     
    if row['Shapefactor1']<=0.5:
           
           shape1='Elongated'
    else:
            shape1='Compact'
            
    if row['Shapefactor2']<=0.5:
        shape2='Oval'
    else:
        shape2='Circular'
        
    if row['Shapefactor3']>=0.9:
        shape3='Circular'
    else:
        shape3='Elongated'     
        
    if row['Shapefactor4']>=0.9:
        shape4='Ellipse'
    else:
        shape4='Irregular'
        
    return f"{shape1},{shape2},{shape3},{shape4}"



def process_SAMmasks(SAM_masks, output_folder):
     
        """
        Calculates the features from metadata files and binary masks generated by Automatic mask generation by Segmentanything model. It analyzes the data, filters the bean masks,
        checks the circularity of beans, creates annotated combined binary mask for each image, calculates the seed count and extracts the 
        features of beans in pixels using image processing libraries. It also standardizes the features from pixels to metric units and saves 
        the annotated binary masks, features .csv files and seed count .xlsx files in the output folder. 

        Arguments:
          SAM_masks: The folder containing the subfolders for each image with binary masks and metadata.Expects the
          binary masks in .png format, with pixel values in [0, 255] and a metadata file in .csv format generated by Segmentanything model SAM.
         output_folder: The output folder where the annotated binary masks, feature extraction .csv file and seed count .xlxs will be saved.

         Raises:
        TypeError: If the conditions are not met.
    
        """   
        
        if not os.path.exists(SAM_masks):
                print(f"Error: SegmentAnything masks folder '{SAM_masks}' does not exist.")
                return
        if not os.path.exists(output_folder):
                os.makedirs(output_folder) # make output folder if not created
                print(f"Output folder '{output_folder}' created.")
                
                # Loop through each subfolder in the main folder
                df_total=[]
                for subfolder_name in os.listdir(SAM_masks):
                        subfolder_path = os.path.join(SAM_masks, subfolder_name)
    
                        #create an empty list 
                        df_list=[]
                
             
                        # Check if it's a directory
                        if os.path.isdir(subfolder_path):
                                print(f'Opening subfolder: {subfolder_path}')
                
                                # Open the metadata file for each image
                                csv_file = glob.glob(os.path.join(subfolder_path, '*.csv'))
    
                                # Read the CSV file into a pandas DataFrame
                                df_metadata = pd.read_csv(csv_file[0])                
          
                                # dataframe for coin required for standardization of area, length and width
                                df_metadata_coin = df_metadata[(df_metadata['bbox_x0'] >= 3000) & (df_metadata['area'] >= 200000)]
                
                                # Find the mask of coin
                                Mask_index1= df_metadata_coin.index.tolist()
                                
                                # Since there can be many masks of coin, take the first mask of coin
                                Mask_index=Mask_index1[:1]
                                               
                                # print the index of coin mask
                                print ('Index of coin mask is ', Mask_index)
       
                                # Eliminating the non-specific masks to get the required bean masks 
                                conditions = [
                                        (df_metadata['bbox_x0'] <= 2800) & (df_metadata['bbox_y0'] <= 1950), #Colorcard
                                        (df_metadata['bbox_x0'] <= 1900) & (df_metadata['bbox_y0'] >= 4650), #label
                                        (df_metadata['bbox_x0'] <= 4000) & (df_metadata['bbox_y0'] >= 5200), #Scale
                                        (df_metadata['bbox_x0'] >= 3000) & (df_metadata['bbox_y0'] >= 4400), #coin
                                        (df_metadata['bbox_h'] >= 700), #duplicate mask for seed
                                        (df_metadata['bbox_w'] >= 700) ] #duplicate mask for seed

                                # Eliminating the non-specific masks to get the required bean masks
                                for condition in conditions:
                                        df_metadata = df_metadata.drop(df_metadata[condition].index)
    
                                # List of mask filenames (without extensions)
                                mask_filenames=df_metadata.index.to_list()
                                print ("The list of bean masks after removing the non-specific masks are ", mask_filenames)

                                # Initialize the combined mask as None
                                combined_mask = None

                                # Define the circularity threshold
                                circularity_threshold = 0.7
                
                # Loop through the list of mask filenames
                                for mask_filename in mask_filenames:
            
                # Construct the full file path
                                        file_path = os.path.join(subfolder_path, f'{mask_filename}.png')
                                        
                # Load each binary mask as grayscale
                                        mask = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)
    
                                        if mask is None:
                                                print(f"Warning: {file_path} not found or couldn't be loaded.")
                                                continue  # Skip if the mask is not found
                                        
                                        # Find contours
                                        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                                        
                                        # Check if any contour satisfies the circularity condition
                                        include_mask = False
                                        for contour in contours:
                                            area = cv2.contourArea(contour)  #calculate the area
                                            perimeter = cv2.arcLength(contour, True) # calculate the perimeter
                                            if perimeter > 0:  # Avoid division by zero
                                                circularity = (4 * np.pi * area) / (perimeter ** 2) #calculate the circularity



                                                if circularity > circularity_threshold: # check for circularity greater than the threshold value
                                                    include_mask = True # if circularity is greater, use the mask
                                                    break  # No need to check further contours in this mask
                                        if include_mask:
                                            print(f"Mask {mask_filename} passes circularity check.")

                                            # Add the true mask to the combined mask
                                            if combined_mask is None:
                                                combined_mask = mask.copy()
                                            else:
                                                combined_mask = cv2.bitwise_or(combined_mask, mask) # combine all masks
                                        else:
                                            print(f"Mask {mask_filename} does not pass circularity check.")
                    
                                        
                                # Convert the result back to binary
                                _, combined_mask = cv2.threshold(combined_mask, 127, 255, cv2.THRESH_BINARY)
        
                                # Find contours in the binary mask
                                contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

                                # Create a copy of the mask or create a blank canvas to draw the contours on
                                contour_image = cv2.cvtColor(combined_mask, cv2.COLOR_GRAY2BGR)  # Convert to color if needed

                                # Draw the contours on the image
                                # -1 draws all contours, (0, 255, 0) is the color (green in BGR), and 2 is the thickness of the contour lines
                                cv2.drawContours(contour_image, contours, -1, (0, 0, 255),15)

                                # Plot the result using Matplotlib: Uncomment for visualization on jupyter notebook
                                # plt.figure()
                                # plt.imshow(cv2.cvtColor(contour_image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for Matplotlib
                                # plt.title("Contours around Object")
                                # plt.axis('off')  
                                # plt.show()
                                
                                                               
                                # Generate the output file name using the subfolder name
                                output_file_name = f"{subfolder_name}_combined_mask.png"

                                # Construct the full path for saving
                                output_file_path = os.path.join(output_folder, output_file_name)

                                # Save the combined mask to the output folder
                                cv2.imwrite(output_file_path, contour_image)
                                print(f"Combined mask saved at: {output_file_path}")
       
                                
#Label the mask
#Reference: https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_label.html
                                label_image = measure.label(combined_mask)

#analyse masks
#Reference: https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.regionprops
#props = regionprops_table(label_image,properties=('area','perimeter','axis_major_length', 'axis_minor_length')) 

                                props = regionprops_table(label_image,properties=('centroid','bbox','area','eccentricity', 'equivalent_diameter_area','perimeter','solidity', 'area_convex', 'extent','axis_major_length', 'axis_minor_length'))

# convert to dataframe
                                df_FE = pd.DataFrame(props)
                                
#Reference:https://www.sciencedirect.com/science/article/pii/S0168169919311573#bi005
                                df_FE = df_FE.assign(Aspect_Ratio=lambda x:(x["axis_major_length"]/x["axis_minor_length"])) # calculate the aspect ratio using mathematical operations
                                df_FE = df_FE.assign(Roundness=lambda x:((4*3.14*(x["area"]))/((x["perimeter"])**2))) # calculate the Roundness using mathematical operations
                                df_FE = df_FE.assign(Compactness=lambda x:(x["equivalent_diameter_area"]/x["axis_major_length"])) # # calculate the Compactness using mathematical operations
                                df_FE["Circularity_SAM"] = (1/(df_FE["Roundness"]))
                                 #Shape features calculation using mathematical operations
                                df_FE= df_FE.assign(Shapefactor1=lambda x: (x["axis_major_length"]/x["area"])) 
                                df_FE= df_FE.assign(Shapefactor2=lambda x: (x["axis_minor_length"]/x["area"]))
                                df_FE["Shapefactor3"] = (df_FE["area"])/(((df_FE["axis_major_length"])/2)*((df_FE["axis_major_length"])/2)*3.14) 
                                df_FE["Shapefactor4"] = (df_FE["area"])/(((df_FE["axis_major_length"])/2)*((df_FE["axis_minor_length"])/2)*3.14)
                                
                                class_in_image=(subfolder_name).split('.JPG')[-1] # used the folder name for class 
                                df_FE["class"]= (subfolder_name).split('.JPG')[-1]
                                print (df_FE)
                                print ("No. of seeds: ", len(df_FE.index))

#Standardize the units from pixels to mm
       
                                for mask_filename in Mask_index:

# Construct the full file path for masks
                                        file_path = os.path.join(subfolder_path, f'{Mask_index[0]}.png')
        
# Load the binary mask of coin as grayscale
                                        mask_coin = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)

                                        #label the mask and calculate the properties using Scikitimage library
                                        label_image = measure.label(mask_coin)
                                        props = regionprops_table(label_image,properties=('area','perimeter','axis_major_length', 'axis_minor_length')) 
                                        coin_std = pd.DataFrame(props)
            #print (coin_std)
            
                                        Length_coin_mm=23.88
                                        width_coin_mm=23.88

                                        Area_standard_coin_pixels= coin_std.iloc[0]['area'] # Area of coin in pixels
                                        Area_Standard_coin_mm2=3.14*(Length_coin_mm/2)*(Length_coin_mm/2) # Area of coin in mm2
                                        Calibration_factor_area=(Area_Standard_coin_mm2/Area_standard_coin_pixels) # Calibration factor for area


                                        axis_major_length_pixels= coin_std.iloc[0]['axis_major_length'] # Length of coin in pixels
                                        Calibration_factor_length=(Length_coin_mm/axis_major_length_pixels) # Calibration factor for length

                                        axis_minor_length_pixels= coin_std.iloc[0]['axis_minor_length'] # Width of coin in pixels
                                        Calibration_factor_width=(width_coin_mm/axis_minor_length_pixels) # Calibration factor for width

                                        perimeter_mm =(2*3.14*Length_coin_mm)/2
                                        perimeter_pixels= coin_std.iloc[0]['perimeter'] # perimeter of coin in pixels
                                        Calibration_factor_perimeter=(perimeter_mm/perimeter_pixels) # Calibration factor for perimeter

                                        df_FE["Area_mm2_SAM"]=df_FE["area"] * Calibration_factor_area
                                        df_FE["Length_mm_SAM"]=df_FE["axis_major_length"] * Calibration_factor_length
                                        df_FE["Width_mm_SAM"]=df_FE["axis_minor_length"] * Calibration_factor_width
                                        df_FE["perimeter_mm_SAM"]=df_FE["perimeter"] * Calibration_factor_perimeter
                                        print (df_FE)
            #print (df_FE)
                                df_list.append(df_FE)
                        df_FE2 = pd.concat(df_list)
                        df_total.append(df_FE2)
                df_image=pd.concat(df_total)
                df_image['Shape']=df_image.apply(classify_shape, axis=1)
                df_image = df_image.loc[:, ['class','Area_mm2_SAM', 'Length_mm_SAM', 'Width_mm_SAM', 'perimeter_mm_SAM', 'Shape', 'centroid-0', 'centroid-1',
                                              'bbox-0', 'bbox-1', 'bbox-2', 'bbox-3', 'area', 'eccentricity', 'equivalent_diameter_area', 
                                              'perimeter', 'solidity', 'area_convex', 'extent', 'axis_major_length', 'axis_minor_length', 
                                              'Aspect_Ratio','Roundness', 'Compactness', 'Circularity_SAM','Shapefactor1', 'Shapefactor2','Shapefactor3', 
                                              'Shapefactor4']]
                df_image.rename(columns={'class': 'Class', 'eccentricity':'Eccentricity', 
                                        'area':'Area_pix_SAM', 'eccentricity':'Eccentricity', 'axis_major_length':'Axis Major Length(pix)_SAM',  
                                        'axis_minor_length':'Axis Minor Length(pix)_SAM'}, 
                                        inplace=True)
                df_image.index.names = ['Seed No. per image']
                print (df_image)
                count_seed=df_image.value_counts("Class").to_frame()
                count=count_seed.rename(columns={'Class':'Class_ID', 'count':'Seed Count'})
                print (count)
                
        
#Save the final file of feature extraction from all images into output folder
                output_filename = f"Fava_bean_Features_extraction.csv"
                output_path= os.path.join(output_folder, output_filename)
                df_image.to_csv(output_path)
                print ("Dimensional and Shape feature extraction from fava bean images is completed.")

#Save the Seed Count data from all images into output folder
             
                output_filename = f"Seed Count.xlsx"
                output_path= os.path.join(output_folder, output_filename)
                count.to_excel(output_path)
                print ("Seed count from fava bean images is completed.")
      
if __name__ == "__main__":
    # Create ArgumentParser object
    parser = argparse.ArgumentParser(description="Process files from input folder to output folder.")

    # Add arguments for input and output folders
    parser.add_argument("SAM_masks", help="Path to the SAM masks")
    parser.add_argument("output_folder", help="Path to the output folder")

    # Parse the command-line arguments
    args = parser.parse_args()

    # Call the process_folders function with provided input and output folders
    process_SAMmasks(args.SAM_masks, args.output_folder)
